# Home Energy Management System with Reinforcement Learning

[![Python](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Research](https://img.shields.io/badge/research-bachelor%20thesis-orange.svg)](https://github.com/VincenzoImp/bachelor-degree-thesis)

> An intelligent Home Energy Management System (HEMS) that uses Artificial Neural Networks and Multi-Agent Reinforcement Learning to optimize electric vehicle charging and household energy consumption.

## ğŸ¯ Overview

This project implements and evaluates four different models for integrating Plug-in Electric Vehicle (PEV) battery management into a smart home energy system. The system combines:

- **Artificial Neural Networks (ANN)** for electricity price prediction
- **Multi-Agent Reinforcement Learning (MARL)** for optimal decision making
- **Real-world data integration** from Nordic electricity markets and EV usage patterns

## ğŸš— Problem Statement

Electric vehicles are becoming increasingly popular, but their charging patterns can significantly impact household energy costs and grid stability. This project addresses:

- **Peak demand issues** when EVs charge simultaneously after work hours
- **High electricity costs** during peak pricing periods
- **Grid stability concerns** from uncoordinated charging
- **User convenience** vs. energy cost optimization trade-offs

## ğŸ§  Technical Approach

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Price Data    â”‚â”€â”€â”€â–¶â”‚  Neural Network  â”‚â”€â”€â”€â–¶â”‚ Price Predictionâ”‚
â”‚   (Nord Pool)   â”‚    â”‚   (18 inputs)    â”‚    â”‚   (24h ahead)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Device Agents  â”‚â—€â”€â”€â”€â”‚      HEMS        â”‚â—€â”€â”€â”€â”‚  Q-Learning     â”‚
â”‚ (EV, HVAC, etc.)â”‚    â”‚   Coordinator    â”‚    â”‚   Optimizer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Price Prediction Module** (`ANN`)
   - 18 input features (time, weather, historical prices)
   - Sigmoid activation function
   - Levenberg-Marquardt training algorithm

2. **Multi-Agent Decision System** (`MARL`)
   - Independent Q-learning agents for each device
   - Îµ-greedy exploration strategy
   - Distributed optimization approach

3. **Battery Management Models** (4 implementations)
   - Non-Shiftable, Shiftable, NaÃ¯f, and Controllable approaches

## ğŸ“Š Models Implemented

### 1. Non-Shiftable Battery (`NSL_Battery`)
**Baseline model** - Charges immediately when plugged in
- âœ… Simple implementation
- âŒ No cost optimization
- ğŸ¯ Reference point for comparisons

### 2. Shiftable Battery (`SL_Battery`) 
**Time-shifting model** - Delays charging to optimal windows
- âœ… Significant cost savings (up to 1.99% improvement)
- âœ… Reduces peak demand
- âŒ Must charge continuously once started
- ğŸ”§ Parameters: `k` (inconvenience cost), `Tne` (charging duration)

### 3. NaÃ¯f Battery (`Naif_Battery`)
**Greedy optimization** - Charges during cheapest available hours
- âœ… Best overall performance (up to 16.89% improvement)
- âœ… Can split charging across multiple periods
- âœ… Simple yet effective algorithm
- ğŸ”§ Parameters: `deficit` (charge level target)

### 4. Controllable Battery (`CL_Battery`)
**Continuous optimization** - Adjusts charging power dynamically
- âœ… Maximum flexibility (up to 3.43% improvement)
- âœ… Real-time adaptation
- âŒ Most complex implementation
- ğŸ”§ Parameters: `Î²` (satisfaction cost), `action_number` (power levels)

## ğŸ“ˆ Performance Results

### Scenario Analysis

The system was evaluated across three scenarios with different user priorities:

| Scenario | Cost Focus | Comfort Focus | Best Model | Improvement |
|----------|------------|---------------|------------|-------------|
| Ï = 0.3  | 70%        | 30%          | NaÃ¯f_Battery.2 | 16.89% |
| Ï = 0.5  | 50%        | 50%          | NaÃ¯f_Battery.0 | 10.76% |
| Ï = 0.8  | 20%        | 80%          | NaÃ¯f_Battery.0 | 4.30% |

### Key Findings

- **NaÃ¯f Battery models** consistently outperformed complex RL approaches
- **Flexibility beats optimization** - ability to split charging sessions was crucial
- **Context matters** - optimal strategy depends on user priorities
- **Diminishing returns** - simple heuristics often sufficient

## ğŸ“ Project Structure

```
bachelor-degree-thesis/
â”œâ”€â”€ main.py                 # Main HEMS simulation engine
â”œâ”€â”€ get_newprofile.py      # Data preprocessing script
â”œâ”€â”€ show_results.py        # Results analysis and visualization
â”œâ”€â”€ comparison.py          # Model comparison utilities
â”œâ”€â”€ latex/                 # Thesis documentation (LaTeX)
â”‚   â””â”€â”€ main.tex
â”œâ”€â”€ data/                  # Sample datasets
â”‚   â”œâ”€â”€ energy_prices.csv
â”‚   â”œâ”€â”€ pev_usage.csv
â”‚   â””â”€â”€ home_profiles.csv
â””â”€â”€ README.md
```

## ğŸ”§ Implementation Details

### Device Classes

Each battery model inherits from base classes with specific behaviors:

```python
class SL_Battery(Shiftable_load):
    def function(self):
        # Q-learning training loop
        for episode in range(loops):
            # Simulate charging scenarios
            # Update Q-table based on rewards
        
        # Execute optimal action
        return energy_consumed, utility_cost
```

### Q-Learning Implementation

```python
# Q-value update rule
Q[state][action] = Q[state][action] + learning_rate * (
    reward + discount_factor * max(Q[next_state]) - Q[state][action]
)
```

### Reward Function

Balances cost optimization with user satisfaction:

```python
def get_reward(self, price_index, start_time, energy_consumed):
    cost_component = (1-p) * price[price_index] * energy_consumed
    satisfaction_component = p * (k * (start_time - preferred_time))
    return 1 / (cost_component + satisfaction_component + epsilon)
```

## ğŸ“Š Data Sources

- **Electricity Prices**: [Nord Pool](https://www.nordpoolgroup.com/) (2013-2014)
- **EV Usage Patterns**: [Test-An-EV Project](http://smarthg.di.uniroma1.it/Test-an-EV)
- **Home Energy Data**: [SmartHG Project](http://smarthg.di.uniroma1.it)

## ğŸ§ª Evaluation Metrics

The system evaluates performance using four key criteria:

1. **Î”% Energy Cost** - Total electricity cost reduction
2. **Î”% Energy Consumed** - Change in total energy consumption  
3. **Î”% Average Charging Price** - Average cost per kWh charged
4. **Î”% Average Final SOC** - Battery charge level achieved

**Overall Score**: `(1-Ï) Ã— (cost_metrics) - Ï Ã— (satisfaction_metrics)`

## ğŸ› ï¸ Customization

### Adding New Battery Models

1. Create a new class inheriting from appropriate base class
2. Implement the `function()` method with your optimization logic
3. Add initialization in `insert_devices()` function
4. Configure parameters in the device list

### Modifying Reward Functions

Customize the reward calculation to reflect different optimization objectives:

```python
def custom_reward(self, price, energy, time_delay, battery_health):
    return weighted_sum([
        price_component(price, energy),
        comfort_component(time_delay), 
        longevity_component(battery_health)
    ])
```

## ğŸ“š Research Context

This implementation is based on the research paper:

> Lu, Renzhi et al. "Demand Response for Home Energy Management Using Reinforcement Learning and Artificial Neural Network" IEEE Transactions on Smart Grid 10 (2019): 6629-6639.

**Key Contributions**:
- Extended original work to focus on EV integration
- Implemented four distinct battery management strategies
- Comparative analysis across multiple user preference scenarios
- Real-world data validation with Nordic electricity markets

## ğŸ“ Academic Usage

This project was developed as a bachelor's thesis in Computer Science at Sapienza University of Rome. If you use this work in academic research, please cite:

```bibtex
@mastersthesis{imperati2021hems,
  title={Valutazione di un Home Energy Management System basato su Reinforcement Learning},
  author={Imperati, Vincenzo},
  year={2021},
  school={Sapienza UniversitÃ  di Roma},
  type={Bachelor's thesis}
}
```

## ğŸ”¬ Future Enhancements

- [ ] **Real-time Integration** - Connect with actual smart home devices
- [ ] **Weather Integration** - Incorporate weather forecasting for better predictions
- [ ] **Solar Panel Support** - Add renewable energy generation optimization
- [ ] **Vehicle-to-Grid (V2G)** - Bidirectional energy flow capabilities
- [ ] **Mobile App Interface** - User-friendly control and monitoring
- [ ] **Cloud Deployment** - Scalable cloud-based implementation

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

1. **Algorithm Enhancements** - New optimization strategies
2. **Real-world Testing** - Hardware integration and validation
3. **User Interface** - Better visualization and control tools
4. **Documentation** - Code comments and usage examples
5. **Performance** - Optimization for larger scale deployments

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Vincenzo Imperati**
- ğŸ“ Computer Science Student, Sapienza University of Rome
- ğŸ“§ Email: imperati.1834930@studenti.uniroma1.it
- ğŸ‘¨â€ğŸ« Supervisor: Prof. Igor Melatti

## ğŸ™ Acknowledgments

- **Prof. Igor Melatti** - Thesis supervisor and guidance
- **Nord Pool** - Historical electricity price data
- **Test-An-EV Project** - Real-world EV usage patterns
- **SmartHG Project** - Home energy consumption datasets
- **IEEE Smart Grid Community** - Research foundation and inspiration